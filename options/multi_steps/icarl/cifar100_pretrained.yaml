######### Basic Settings #########
basic:
    device: '4'
    seed: [1993] # 1, 42, 50, 100, 1993

    # Dataset Choises: cifar100, cifar100, imagenet100, imagenet1000, tinyimagenet,
    # skin7, sd198(also known as skin40), mymedmnist
    dataset: cifar100
    shuffle: false

    # Method Choises: icarl, end2end, dr, ucir, bic, lwm, podnet, mas, jointï¼Œ finetune
    method: icarl
    method_type: multi_steps
    # eval_metric Choises: acc, recall
    eval_metric: acc

    # Backbone Choises: resnet18, resnet18_cbam, cosine_resnet18, 
    # resnet32, cosine_resnet32, resnet34, cosine_resnet34, resnet50, vit_base_patch16_224
    backbone: resnet18
    pretrained: true
    save_models: true # if true, programm will save model's weights during incremental train
    checkpoint_dir: "/home/21/zejun/Storage/CL_code/IL_Framework/logs/multi_step/icarl_cil_replay_herding/cifar100/resnet18_b10i10/icarl_res18_pretrained/"
    ######### Exampler Hyperparameters #########
    memory_size: 2000
    fixed_memory: false
    sampling_method: herding # herding, random, closest_to_mean 

    apply_nme: true

    ######### Task Settings, unimportant in Joint #########
    # for some datasets(e.g. MedMNist), this will be ignored
    split_dataset: true
    init_cls: 10
    increment: 10
    prompt_num: 20
    top_k: 3
    manual_temp: false
    note: icarl_res18_pretrained
    # test_epoch: 10

######### Method's Hyperparameters #########
special:
    incre_type: cil
    T: 2

######### Experiment Settings for Datasets #########
options:
    # experiment settings for cifar100
    cifar100:
        resnet18:
            img_size: 224

            epochs: 110 # 200
            batch_size: 32
            num_workers: 4
            
            # opt_type: adam
            opt_type: sgd
            lrate: 0.001
            weight_decay: 0.0005
            opt_mom: 0.9
            
            scheduler: multi_step
            milestones: [49, 63, 90]
            lrate_decay: 0.1
            
        mobilenet_v2:
            img_size: 224

            epochs: 200 # 200
            batch_size: 64
            num_workers: 4

            # opt_type: adam
            opt_type: sgd
            lrate: 0.01
            weight_decay: 0.0005
            opt_mom: 0.9
            
            scheduler: multi_step
            milestones: [70, 130, 170]
            lrate_decay: 0.1

        efficientnet_b0:
            img_size: 224

            epochs: 200 # 200
            batch_size: 64
            num_workers: 4
            
            # opt_type: adam
            opt_type: sgd
            lrate: 0.01
            weight_decay: 0.0005
            opt_mom: 0.9
            
            scheduler: multi_step
            milestones: [70, 130, 170]
            lrate_decay: 0.1
        
        vit_base_patch16_224_clip:
            img_size: 224

            epochs: 200 # 200
            batch_size: 32 # 64
            num_workers: 8
            
            # opt_type: adam
            opt_type: sgd
            lrate: 0.01
            weight_decay: 0.0005
            opt_mom: 0.9
            
            scheduler: multi_step
            milestones: [70, 130, 170]
            lrate_decay: 0.1
        
        vit_base_patch16_224:
            img_size: 224

            epochs: 50 # 200
            batch_size: 32 # 64
            num_workers: 8
            
            # opt_type: adam
            opt_type: sgd
            lrate: 0.01
            weight_decay: 0.0005
            opt_mom: 0.9
            
            scheduler: multi_step
            milestones: [20,35,45]  # [70, 130, 170]
            lrate_decay: 0.1
