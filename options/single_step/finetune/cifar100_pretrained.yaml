######### Basic Settings #########
basic:
    device: '6'
    seed: [1993]

    # Dataset Choises: cifar100, cifar100, imagenet100, imagenet1000, tinyimagenet,
    # skin7, sd198(also known as skin40), mymedmnist
    dataset: cifar100
    shuffle: true

    # Method Choises: 
    method: finetune_normal
    method_type: single_step
    # eval_metric Choises: acc, recall
    eval_metric: acc

    # Backbone Choises: resnet18, resnet18_cbam, cosine_resnet18, 
    # resnet32, cosine_resnet32, resnet34, cosine_resnet34, resnet50
    backbone: vit_base_patch16_224_clip
    pretrained: true
    freeze_fe: false
    save_models: true # if true, programm will save model's weights during incremental train

    # for more efficient experiment
    # split_dataset: true
    # init_cls: 10
    # increment: 10

    note: fine_tune_pretrain_lr0.001

######### Method's Hyperparameters #########
# special:
    

######### Experiment Settings for Datasets #########
options:
    # experiment settings for cifar100
    cifar100:        
        resnet18:
            img_size: 224

            epochs: 200 # 340
            batch_size: 64
            num_workers: 4

            opt_type: sgd
            lrate: 0.001
            weight_decay: 0.0005
            opt_mom: 0.9
            
            scheduler: multi_step
            milestones: [70, 130, 170]
            lrate_decay: 0.1
            
        resnet32:
            epochs: 200 #80
            batch_size: 128
            num_workers: 8

            opt_type: sgd
            lrate: 0.001
            weight_decay: 0.0005
            opt_mom: 0.9        
    
            scheduler: multi_step
            milestones: [60,120,160]
            lrate_decay: 0.1
        
        vit_base_patch16_224_clip:
            img_size: 224

            epochs: 200 #80
            batch_size: 32
            num_workers: 8

            opt_type: adamw
            lrate: 0.00001
    
            scheduler: cos

        vit_base_patch16_224:
            img_size: 224

            epochs: 200 #80
            batch_size: 32
            num_workers: 8

            opt_type: adam
            lrate: 0.001
    
            scheduler: cos